# Notes for October 

## To do

- [x] Store data locally 
- [] Ensure a long sentence is broken up into pieces 

### Ensure a long sentence is broken up into pieces

What do I want to happen?

The transformer only takes in a certain number of tokens as input. 
A token is an embedding generated by the tokenizer. 
Can be some combination of char level or word level.

Sometimes the input sequence for a given row is very long.
Right now we are specifying that these rows should be truncated.
Rather we want the tokenizer to continue where it left off. 


